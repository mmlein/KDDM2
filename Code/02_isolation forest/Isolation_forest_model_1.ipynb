{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pyod\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path(\"C:/Users/Dani/Documents/Coding/kddm2/Data/letter-recognition.data\")\n",
    "\n",
    "header = list(range(1, 17))\n",
    "header = [\"letter\"] + header\n",
    "\n",
    "letter_df_complete = pd.read_csv(path_data, \n",
    "sep = \",\", \n",
    "names = header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.iforest import IForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Prepare dataset\n",
    "def prepare_dataset(letter, dataset=letter_df_complete, test_prob = 0.2, rand_state = 0):\n",
    "    #Filter for the letter\n",
    "    dataset_letter = dataset[dataset[\"letter\"] == letter]\n",
    "\n",
    "    #Create a copy of the dataset without the letter\n",
    "    dataset_wo_let = dataset_letter.drop('letter', axis = 1)\n",
    "\n",
    "    #Split the dataset into training and test data\n",
    "    letter_train, letter_test = train_test_split(dataset_wo_let, test_size = test_prob, random_state = rand_state)\n",
    "\n",
    "    return dataset_letter, letter_train, letter_test\n",
    "\n",
    "#Statistical function to count outliers (https://towardsdatascience.com/use-the-isolated-forest-with-pyod-3818eea68f08)\n",
    "def count_stat(vector):\n",
    "    # Because it is '0' and '1', we can run a count statistic. \n",
    "    unique, counts = np.unique(vector, return_counts=True)\n",
    "    return dict(zip(unique, counts))\n",
    "\n",
    "def isolation_forest(train_data, test_data, cont=0.05, max_feat=1.0, max_samp=40, n_est=100, random_state=0):\n",
    "    #Create a new iForest\n",
    "    isft = IForest(behaviour='new', contamination=cont, max_features=max_feat, max_samples=max_samp, n_estimators=n_est)\n",
    "    #'behaviour': 'new',                    for decision function change to match other anomaly detection algorithm API\n",
    "    #'bootstrap': False,                    bootstrapping applied or not\n",
    "    #'contamination': 0.1,          % of outliers in dataset\n",
    "    #'max_features': 1.0,           number of features from X\n",
    "    #'max_samples': 40,             number of samples to draw (size of a tree)\n",
    "    #'n_estimators': 100,           number of trees in ensemble\n",
    "    #'n_jobs': 1,                           parallel jobs to be done\n",
    "    #'random_state': None,                  random state\n",
    "    #'verbose': 0                           verbosity of the tree\n",
    "\n",
    "    #Fit iForest\n",
    "    isft.fit(train_data)\n",
    "\n",
    "    #Training data\n",
    "    y_train_scores = isft.decision_function(train_data)\n",
    "    y_train_pred = isft.predict(train_data)\n",
    "\n",
    "    #Test data\n",
    "    y_test_scores = isft.decision_function(test_data)\n",
    "    y_test_pred = isft.predict(test_data)\n",
    "\n",
    "    #Threshold for defined contamination rate\n",
    "    #print(\"The threshold for the defined contamination rate:\" , isft.threshold_)\n",
    "\n",
    "    #print(\"The training data:\", count_stat(y_train_pred))\n",
    "    #print(\"The testing data:\", count_stat(y_test_pred))\n",
    "    return isft, y_train_scores, y_test_scores\n",
    "\n",
    "def var_importance(iso_for, let_train):\n",
    "    isft_vi = iso_for.feature_importances_\n",
    "    #print(isft_vi)\n",
    "\n",
    "    for_plot = pd.DataFrame({'x_axis':let_train.columns,\n",
    "              'y_axis':isft_vi}).sort_values(by='y_axis',ascending=True)\n",
    "    for_plot['y_axis'].plot.barh()\n",
    "\n",
    "def plot_train_scores(train_dataset_scores):\n",
    "    plt.hist(train_dataset_scores, bins='auto') # arguments are passed to np.histogram\n",
    "    plt.title(\"Outlier score\")\n",
    "    plt.show()\n",
    "\n",
    "def descriptive_stat_threshold(df, pred_score, threshold):\n",
    "    # Let's see how many '0's and '1's.\n",
    "    df = pd.DataFrame(df)\n",
    "    df['Anomaly_Score'] = pred_score\n",
    "    df['Group'] = np.where(df['Anomaly_Score']< threshold, 'Normal', 'Outlier')\n",
    "\n",
    "    # Now let's show the summary statistics:\n",
    "    cnt = df.groupby('Group')['Anomaly_Score'].count().reset_index().rename(columns={'Anomaly_Score':'Count'})\n",
    "    cnt['Count %'] = (cnt['Count'] / cnt['Count'].sum()) * 100 # The count and count %\n",
    "    stat = df.groupby('Group').mean().round(2).reset_index() # The avg.\n",
    "    stat = cnt.merge(stat, left_on='Group',right_on='Group') # Put the count and the avg. together\n",
    "    return (stat)\n",
    "\n",
    "def full_iso_tree(letter, letter_df_comp=letter_df_complete, cont=0.1, max_feat=1.0, max_samp=40, n_est=100, random_state=0, plot_bool=False):\n",
    "    #print(letter)\n",
    "    letter_df, df_train, df_test = prepare_dataset(letter, letter_df_comp)\n",
    "    isft_letter, df_train_scores, df_test_score = isolation_forest(df_train, df_test, cont=0.1, max_feat=1.0, \n",
    "        max_samp=40, n_est=100, random_state=0)\n",
    "    if plot_bool == True:\n",
    "        plot_train_scores(df_train_scores)\n",
    "        var_importance(isft_letter, df_train)\n",
    "    threshold_df = isft_letter.threshold_ # Or other value from the above histogram\n",
    "    stat_df = descriptive_stat_threshold(df_train, df_train_scores, threshold_df)\n",
    "    #print(letter, \"\\n\", descriptive_stat_threshold(df_train, df_train_scores, threshold_df))\n",
    "    return stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "     Group  Count    Count %     1      2     3     4     5     6     7     8  \\\n",
      "0   Normal    611  94.875776  3.86   6.97  5.02  5.14  3.86  7.45  6.84  6.02   \n",
      "1  Outlier     33   5.124224  7.15  11.64  7.67  7.06  5.91  8.88  5.55  4.21   \n",
      "\n",
      "      9    10    11    12    13    14    15    16  Anomaly_Score  \n",
      "0  6.53  8.07  5.17  5.68  3.27  7.87  3.75  7.66          -0.10  \n",
      "1  6.06  9.94  4.06  7.27  5.45  7.18  6.33  7.67           0.02  \n",
      "1    5.124224\n",
      "Name: Count %, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"D\")\n",
    "letter_d, d_train, d_test = prepare_dataset(letter_df_complete, \"D\")\n",
    "isft_d, d_train_scores, d_test_score = isolation_forest(d_train, d_test)\n",
    "\n",
    "print(\"M\")\n",
    "letter_m, m_train, m_test = prepare_dataset(letter_df_complete, \"M\")\n",
    "isft_m, m_train_scores, m_test_score = isolation_forest(m_train, m_test)\n",
    "\n",
    "print(\"F\")\n",
    "letter_f, f_train, f_test = prepare_dataset(letter_df_complete, \"F\")\n",
    "isft_f, f_train_scores, f_test_score = isolation_forest(f_train, f_test)\n",
    "\"\"\"\n",
    "\n",
    "print(\"D\")\n",
    "letter_d, d_train, d_test = prepare_dataset(\"D\")\n",
    "isft_d, d_train_scores, d_test_score = isolation_forest(d_train, d_test)\n",
    "threshold_df = isft_d.threshold_ # Or other value from the above histogram#\n",
    "stat_df = descriptive_stat_threshold(d_train, d_train_scores, threshold_df)\n",
    "print(stat_df)\n",
    "percentage = stat_df[stat_df['Group'] == 'Outlier']['Count %']\n",
    "print(percentage)\n",
    "\n",
    "#full_iso_tree(\"D\", letter_df_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/71488625/how-to-create-all-possible-combinations-of-parameters-in-a-dictionaryp\n",
    "\n",
    "\n",
    "hyper_params = {\n",
    "    'cont': [0.01, 0.025, 0.05, 0.075, 0.1],\n",
    "    'max_feat': [1, 8, 16],\n",
    "    'max_samp': [10, 50, 100],\n",
    "    'max_est': [10, 25, 50, 100, 250],\n",
    "    'random_state': [0, 1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "def grid_validation(letter, params=hyper_params, letter_df_comp=letter_df_complete):\n",
    "    a = params.values()\n",
    "    combinations = list(itertools.product(*a))\n",
    "\n",
    "    results_df = pd.DataFrame(columns = ['% Outliers', 'Contamination', 'Max Feature', 'Max Sample', 'Max Estimate', 'Random State'])\n",
    "\n",
    "    for c in combinations:\n",
    "        stat_df = full_iso_tree(letter, letter_df_comp, cont=c[0], max_feat=c[1], max_samp=c[2], n_est=c[3], random_state=c[4])\n",
    "        perc_normal = stat_df.loc[stat_df['Group'] == 'Normal', 'Count %'].iloc[0]\n",
    "        if perc_normal >= 100:\n",
    "            perc_outlier = 0.000\n",
    "        else:\n",
    "            perc_outlier = stat_df.loc[stat_df['Group'] == 'Outlier', 'Count %'].iloc[0]\n",
    "        results_df = results_df.append({'% Outliers': perc_outlier, 'Contamination': c[0], 'Max Feature': c[1], \n",
    "            'Max Sample': c[2], 'Max Estimate': c[3]}, ignore_index = True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results_df):\n",
    "    print(results_df.head())\n",
    "    print(results_df['% Outliers'].describe())\n",
    "\n",
    "    plt.hist(results_df['% Outliers'])\n",
    "    plt.show()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    x = np.arange(0, 900, 1)\n",
    "    y = results_df['% Outliers']\n",
    "\n",
    "    ax.plot(y, color='blue', label='Outliers')\n",
    "\n",
    "    plt.ylim([9, 11])\n",
    "    plt.show()\n",
    "\n",
    "    plt.boxplot(results_df['% Outliers'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_d = grid_validation(\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m = grid_validation(\"M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_f = grid_validation(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.combination import aom, moa, average, maximization\n",
    "from pyod.utils.utility import standardizer\n",
    "from pyod.models.iforest import IForest\n",
    "\n",
    "letter_d, d_train, d_test = prepare_dataset(letter_df_complete, \"D\")\n",
    "\n",
    "# Test a range of the number of trees\n",
    "k_list = [100, 200, 300, 400, 500]\n",
    "n_clf = len(k_list)\n",
    "# Just prepare data frames so we can store the model results\n",
    "train_scores = np.zeros([d_train.shape[0], n_clf])\n",
    "test_scores = np.zeros([d_test.shape[0], n_clf])\n",
    "\n",
    "# Modeling\n",
    "for i in range(n_clf):\n",
    "    k = k_list[i]\n",
    "    #isft = IForest(contamination=0.05, max_samples=k) \n",
    "    isft = IForest(contamination=0.05, n_estimators=k) \n",
    "    isft.fit(d_train)\n",
    "    \n",
    "    # Store the results in each column:\n",
    "    train_scores[:, i] = isft.decision_function(d_train) \n",
    "    test_scores[:, i] = isft.decision_function(d_test) \n",
    "\n",
    "# Combination by average\n",
    "# The test_scores_norm is 500 x 10. The \"average\" function will take the average of the 10 columns. The result \"y_by_average\" is a single column: \n",
    "y_train_by_average = average(train_scores)\n",
    "y_test_by_average = average(test_scores)\n",
    "\n",
    "plt.hist(y_train_by_average, bins='auto') # arguments are passed to np.histogram\n",
    "plt.title(\"Combination by average\")\n",
    "plt.show()\n",
    "\n",
    "descriptive_stat_threshold(d_train,y_train_by_average, 0.00)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2c2ca1c87da01fb52268abc3977c437405da1f8003aa0161136559854c1f177"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
